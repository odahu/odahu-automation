proxy:
  secretToken: ${jupyterhub_secret_token}
  service:
    type: ClusterIP
  https:
    enabled: false
  chp:
    resources:
      requests:
        cpu: 200m
        memory: 512Mi

debug:
  enabled: ${debug_enabled}

scheduling:
  userScheduler:
    resources:
      requests:
        cpu: 50m
        memory: 256Mi

custom:
  jupyterlab: |
    c.Spawner.cmd = ['jupyter-labhub']

hub:
  config:
    GenericOAuthenticator:
      login_service: "keycloak"
      auto_login: true
      client_id: "${oauth_client_id}"
      client_secret: "${oauth_client_secret}"
      token_url: "${oauth_oidc_issuer_url}/protocol/openid-connect/token"
      userdata_url: "${oauth_oidc_issuer_url}/protocol/openid-connect/userinfo"
      userdata_method: GET
      userdata_params: {'state': 'state'}
      username_key: preferred_username
    JupyterHub:
      authenticator_class: oauthenticator.generic.GenericOAuthenticator
  service:
    type: ClusterIP
  baseUrl: /jupyterhub
  extraEnv:
    OAUTH2_AUTHORIZE_URL: ${oauth_oidc_issuer_url}/protocol/openid-connect/auth
    OAUTH2_TOKEN_URL: ${oauth_oidc_issuer_url}/protocol/openid-connect/token
    OAUTH_CALLBACK_URL: https://${cluster_domain}/jupyterhub/hub/oauth_callback
  resources:
    requests:
      cpu: 200m
      memory: 512Mi
%{ if pgsql_enabled }
  db:
    type: postgres
    url: ${pgsql_url}
    password: ${pgsql_password}
%{ else ~}
  db:
    type: sqlite-pvc
    pvc:
      accessModes:
      - ReadWriteOnce
      storage: 1Gi
%{ endif ~}

${ingress}

prePuller:
  hook:
    enabled: ${image_puller}
    resources:
      requests:
        cpu: 0
        memory: 0
  resources:
    requests:
      cpu: 0
      memory: 0

singleuser:
  startTimeout: 900
  serviceAccountName: "${single_user_sa}"
  cloudMetadata:
    blockWithIptables: true
    ip: 169.254.169.254
  networkPolicy:
    enabled: false
    egress:
    # Required egress is handled by other rules so it's safe to modify this
      - to:
          - ipBlock:
              cidr: 0.0.0.0/0
  extraEnv:
    API_AUTH_ENABLED: "false"
    DEFAULT_API_ENDPOINT: "http://odahu-flow-api.odahu-flow.svc.cluster.local:80"
    ODAHUFLOWCTL_OAUTH_CLIENT_ID: "${odahuflowctl_id}"
    ODAHUFLOWCTL_OAUTH_CLIENT_SECRET: "${odahuflowctl_secret}"
    API_URL: "https://${cluster_domain}"
    ISSUER_URL: "${oauth_oidc_issuer_url}"
%{ if cloud_type == "azure" ~}
    AZURE_STORAGE_ACCOUNT: "${azure_account_name}"
    AZURE_STORAGE_SAS_TOKEN: "${azure_sas_token}"
%{ endif ~}
  defaultUrl: "/lab"
  image:
    name: ${docker_repo}/base-notebook
    tag: ${docker_tag}
  profileList:
%{ if deploy_examples == "true" ~}
    - display_name: "Base Jupyter Notebook with examples"
      description: "Base image for Jupyter Notebook with ODAHU plugin and examples cloned to workspace"
      default: true
      kubespawner_override:
        lifecycle_hooks:
          postStart:
            exec:
              command:
                - "sh"
                - "-c"
                - >
                  git clone -b develop https://github.com/odahu/odahu-examples.git
%{ endif ~}
    - display_name: "Base Jupyter Notebook"
      description: "Base image for Jupyter Notebook with ODAHU plugin"
%{ if deploy_examples != "true" ~}
      default: true
%{ endif ~}
    - display_name: "Datascience environment"
      description: "Python, R, and Julia with ODAHU plugin."
      kubespawner_override:
        image: ${docker_repo}/datascience-notebook:${docker_tag}
    - display_name: "Tensorflow environment"
      description: "Jupyter Notebook Scientific Python Stack w/ Tensorflow and ODAHU plugin"
      kubespawner_override:
        image: ${docker_repo}/tensorflow-notebook:${docker_tag}
${culling}
